{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.txt', names=['user', 'item', 'score'], sep='\\t')\n",
    "test = pd.read_csv('./test.txt', names=['user', 'item'], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  score\n",
       "0     1     1      5\n",
       "1     1     2      3\n",
       "2     1     3      4\n",
       "3     1     4      3\n",
       "4     1     5      3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "martix_train = train.pivot_table(columns='item', index='user', values='score').fillna(0).values\n",
    "martix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['score'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched = set()\n",
    "for pair in test.append(train).values[:, :2]:\n",
    "    watched.add(tuple(pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_split(user_item, test_size=0.1):\n",
    "    X_train = np.zeros(user_item.shape)\n",
    "    X_test = np.zeros(user_item.shape)\n",
    "    np.random.seed(1337)\n",
    "    has_score = np.argwhere(user_item > 0)\n",
    "    np.random.shuffle(has_score)\n",
    "    split = int(len(has_score) * test_size)\n",
    "    test = has_score[:split]\n",
    "    train = has_score[split:]\n",
    "    for i, idx in enumerate(train):\n",
    "        X_train[idx[0], idx[1]] = user_item[idx[0], idx[1]]\n",
    "    for i, idx in enumerate(test):\n",
    "        X_test[idx[0], idx[1]] = user_item[idx[0], idx[1]]\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IALS:\n",
    "    \n",
    "    def __init__(self, iterations=30, latent_features=5, alpha=25, lambda_reg=10, neg_sampling=0.85, conf_w=10):\n",
    "        self.iterations = iterations\n",
    "        self.latent_features = latent_features\n",
    "        self.alpha = alpha\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.neg_sampling = neg_sampling\n",
    "        self.conf_w = conf_w\n",
    "        np.random.seed(1337)\n",
    "        \n",
    "    def fit(self, train, test=None):\n",
    "        user_size, item_size = train.shape\n",
    "        matrix_full = np.zeros_like(train)\n",
    "        mean_score = train[(train > 0)].mean()\n",
    "        for u in range(user_size):\n",
    "            for i in range(item_size):\n",
    "                if train[u][i]:\n",
    "                    matrix_full[u][i] = train[u][i]\n",
    "                elif (u, i) in watched:\n",
    "                    matrix_full[u][i] = mean_score\n",
    "                else:\n",
    "                    matrix_full[u][i] = mean_score * self.neg_sampling\n",
    "\n",
    "        C = np.ones(train.shape) + self.alpha * np.log(np.ones(train.shape) + train * self.conf_w)   \n",
    "        C_I = C - 1\n",
    "        lambda_I = self.lambda_reg * sparse.eye(self.latent_features + 1)\n",
    " \n",
    "        # user u x f\n",
    "        X = np.hstack([np.ones((user_size, 1)), np.random.normal(size=(user_size, self.latent_features))])\n",
    "        # item i x f\n",
    "        Y = np.hstack([np.ones((item_size, 1)), np.random.normal(size=(item_size, self.latent_features))])\n",
    "        # biased als\n",
    "        X_bias = np.array([0] * user_size)\n",
    "        Y_bias = np.array([0] * item_size)\n",
    "        \n",
    "        n_user = (train > 0).sum(1)\n",
    "        n_item = (train > 0).sum(0)\n",
    "        \n",
    "        MIN_LOSS = 9999999\n",
    "        MIN_ITER = 9999999\n",
    "        for iteration in range(self.iterations):            \n",
    "            # User step\n",
    "            yTy = np.dot(Y.T, Y)\n",
    "            Cu = C * (matrix_full - Y_bias)\n",
    "            for u in range(user_size):\n",
    "                # X = ((Y.T*Y + Y.T*(C - I) * Y) + lambda*I)^-1 * (Y.T * Cu)\n",
    "                inv = np.linalg.inv(yTy + np.dot(Y.T * C_I[u], Y) + lambda_I * n_user[u])\n",
    "                X[u] = np.dot(np.dot(inv, Y.T), Cu[u].reshape(-1, 1)).ravel()\n",
    "            X_bias = X[:, 0].copy().reshape(-1, 1)\n",
    "            X[:, 0] = 1\n",
    "                \n",
    "            # Item step\n",
    "            xTx = np.dot(X.T, X)\n",
    "            Ci = C * (matrix_full - X_bias)\n",
    "            for i in range(item_size):\n",
    "                # Y = ((X.T*X + X.T*(C - I) * X) + lambda*I)^-1 * (X.T * Ci)\n",
    "                inv = np.linalg.inv(xTx + np.dot(X.T * C_I[:, i], X) + lambda_I * n_item[i])\n",
    "                Y[i] = np.dot(np.dot(inv, X.T), Ci[:, i].reshape(-1, 1)).ravel()\n",
    "            Y_bias = Y[:, 0].copy().ravel()\n",
    "            Y[:, 0] = 1\n",
    "            \n",
    "            result = np.dot(X[:, 1:], Y[:, 1:].T) + X_bias + Y_bias\n",
    "            result[result > 5] = 5\n",
    "            result[result < 1] = 1\n",
    "            \n",
    "            if test is not None:\n",
    "                rmse = np.sqrt(((result * (test > 0) - test) ** 2).sum() / (test > 0).sum())\n",
    "                rmset = np.sqrt(((result * (train > 0) - train) ** 2).sum() / (train > 0).sum())\n",
    "                if rmse < MIN_LOSS:\n",
    "                    MIN_LOSS = rmse\n",
    "                    MIN_ITER = iteration\n",
    "                    #print(\"CUR MIN:\", rmse, iteration, self.latent_features, self.alpha, self.lambda_reg, self.neg_sampling, self.conf_w)\n",
    "                #print(\"Test score:\", str(iteration) + \" | \" + str(rmse) + \" | \" + str(rmset))\n",
    "            else:\n",
    "                rmse = np.sqrt(((result * (train > 0) - train) ** 2).sum() / (train > 0).sum())\n",
    "                #print(\"Train score:\", str(iteration) + \" | \" + str(rmse))\n",
    "                \n",
    "#        return MIN_LOSS, MIN_ITER, self.latent_features, self.alpha, self.lambda_reg, self.neg_sampling, self.conf_w\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from joblib import Parallel, delayed\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID = {\n",
    "    'latent_features': [5, 10, 15],\n",
    "    'alpha': [10, 25, 40, 100],\n",
    "    'lambda_reg': [0.5, 5, 10, 15, 20],\n",
    "    'neg_sampling': [0.5, 0.75, 0.85, 1.0],\n",
    "    'conf_w': [1, 5, 10, 20, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_split(martix_train, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f197ebf375da4d1f89213108fd8b05ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = ParameterGrid(GRID)\n",
    "best_score = 999999\n",
    "\n",
    "def grid_search(dict_):\n",
    "    return IALS(**dict_).fit(X_train, X_test)\n",
    "\n",
    "GS = Parallel(n_jobs=-1)(delayed(grid_search)(dict_) for dict_ in tqdm.tqdm(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9139662442046143, 11, 5, 100, 15, 0.75, 1),\n",
       " (0.9144519547170014, 10, 5, 100, 15, 0.85, 1),\n",
       " (0.9147856216111326, 11, 5, 40, 15, 0.85, 10),\n",
       " (0.9149946763732804, 14, 5, 40, 10, 0.85, 5),\n",
       " (0.9155571578200764, 11, 5, 40, 20, 0.85, 20),\n",
       " (0.9158111653793563, 8, 10, 100, 20, 0.85, 1),\n",
       " (0.9158415430872886, 12, 5, 40, 15, 0.75, 10),\n",
       " (0.9158767554267505, 15, 5, 40, 10, 0.75, 5),\n",
       " (0.9158834603710929, 13, 5, 25, 10, 0.85, 20),\n",
       " (0.9159032701005957, 25, 5, 40, 15, 0.85, 20),\n",
       " (0.9159282695248893, 9, 5, 100, 20, 0.75, 1),\n",
       " (0.9160828203524338, 8, 5, 100, 20, 0.85, 1),\n",
       " (0.9163132854131656, 9, 5, 40, 15, 0.85, 5),\n",
       " (0.9163207303660508, 9, 10, 100, 20, 0.75, 1),\n",
       " (0.9165103356830069, 14, 5, 40, 20, 0.85, 50),\n",
       " (0.9165156567796929, 10, 5, 25, 10, 0.85, 10),\n",
       " (0.9167239313150672, 11, 5, 25, 15, 0.85, 50),\n",
       " (0.9167525893117328, 19, 5, 40, 15, 0.75, 20),\n",
       " (0.9167969535263346, 11, 5, 40, 20, 0.75, 20),\n",
       " (0.9169190198281769, 7, 15, 100, 20, 0.85, 1)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(GS, key=lambda x: x[0])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [(0.9139662442046143, 11, 5, 100, 15, 0.75, 1),\n",
    " (0.9144519547170014, 10, 5, 100, 15, 0.85, 1),\n",
    " (0.9147856216111326, 11, 5, 40, 15, 0.85, 10),\n",
    " (0.9149946763732804, 14, 5, 40, 10, 0.85, 5),\n",
    " (0.9155571578200764, 11, 5, 40, 20, 0.85, 20),\n",
    " (0.9158111653793563, 8, 10, 100, 20, 0.85, 1)]\n",
    "\n",
    "res = np.zeros_like(martix_train)\n",
    "\n",
    "for m in models:\n",
    "    res += IALS(m[1], latent_features=m[2], alpha=m[3], lambda_reg=m[4], neg_sampling=m[5], conf_w=m[6]).fit(martix_train)\n",
    "res = res / len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IALS:\n",
    "    \n",
    "    def __init__(self, iterations=30, latent_features=5, alpha=25, lambda_reg=10, neg_sampling=0.85, conf_w=10):\n",
    "        self.iterations = iterations\n",
    "        self.latent_features = latent_features\n",
    "        self.alpha = alpha\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.neg_sampling = neg_sampling\n",
    "        self.conf_w = conf_w\n",
    "        np.random.seed(1337)\n",
    "        \n",
    "    def fit(self, train, test=None):\n",
    "        user_size, item_size = train.shape\n",
    "        matrix_full = np.zeros_like(train)\n",
    "        mean_score = train[(train > 0)].mean()\n",
    "        for u in range(user_size):\n",
    "            for i in range(item_size):\n",
    "                if train[u][i]:\n",
    "                    matrix_full[u][i] = train[u][i]\n",
    "                else:\n",
    "                    matrix_full[u][i] = res[u][i]\n",
    "                    \n",
    "        C = np.ones(train.shape) + self.alpha * np.log(np.ones(train.shape) + train * self.conf_w)\n",
    "        C_I = C - 1\n",
    "        lambda_I = self.lambda_reg * sparse.eye(self.latent_features + 1)\n",
    " \n",
    "        # user u x f\n",
    "        X = np.hstack([np.ones((user_size, 1)), np.random.normal(size=(user_size, self.latent_features))])\n",
    "        # item i x f\n",
    "        Y = np.hstack([np.ones((item_size, 1)), np.random.normal(size=(item_size, self.latent_features))])\n",
    "        # biased als\n",
    "        X_bias = np.array([0] * user_size)\n",
    "        Y_bias = np.array([0] * item_size)\n",
    "        \n",
    "        n_user = (train > 0).sum(1)\n",
    "        n_item = (train > 0).sum(0)\n",
    "        \n",
    "        MIN_LOSS = 9999999\n",
    "        MIN_ITER = 9999\n",
    "        for iteration in range(self.iterations):            \n",
    "            # User step\n",
    "            yTy = np.dot(Y.T, Y)\n",
    "            Cu = C * (matrix_full - Y_bias)\n",
    "            for u in range(user_size):\n",
    "                # X = ((Y.T*Y + Y.T*(C - I) * Y) + lambda*I)^-1 * (Y.T * Cu)\n",
    "                inv = np.linalg.inv(yTy + np.dot(Y.T * C_I[u], Y) + lambda_I * n_user[u])\n",
    "                X[u] = np.dot(np.dot(inv, Y.T), Cu[u].reshape(-1, 1)).ravel()\n",
    "            X_bias = X[:, 0].copy().reshape(-1, 1)\n",
    "            X[:, 0] = 1\n",
    "                \n",
    "            # Item step\n",
    "            xTx = np.dot(X.T, X)\n",
    "            Ci = C * (matrix_full - X_bias)\n",
    "            for i in range(item_size):\n",
    "                # Y = ((X.T*X + X.T*(C - I) * X) + lambda*I)^-1 * (X.T * Ci)\n",
    "                inv = np.linalg.inv(xTx + np.dot(X.T * C_I[:, i], X) + lambda_I * n_item[i])\n",
    "                Y[i] = np.dot(np.dot(inv, X.T), Ci[:, i].reshape(-1, 1)).ravel()\n",
    "            Y_bias = Y[:, 0].copy().ravel()\n",
    "            Y[:, 0] = 1\n",
    "            \n",
    "            result = np.dot(X[:, 1:], Y[:, 1:].T) + X_bias + Y_bias\n",
    "            result[result > 5] = 5\n",
    "            result[result < 1] = 1\n",
    "            \n",
    "            if test is not None:\n",
    "                rmse = np.sqrt(((result * (test > 0) - test) ** 2).sum() / (test > 0).sum())\n",
    "                rmset = np.sqrt(((result * (train > 0) - train) ** 2).sum() / (train > 0).sum())\n",
    "                if rmse < MIN_LOSS:\n",
    "                    MIN_LOSS = rmse\n",
    "                    MIN_ITER = iteration\n",
    "                    #print(\"CUR MIN:\", rmse, iteration, self.latent_features, self.alpha, self.lambda_reg, self.neg_sampling, self.conf_w)\n",
    "                #print(\"Test score:\", str(iteration) + \" | \" + str(rmse) + \" | \" + str(rmset))\n",
    "            else:\n",
    "                rmse = np.sqrt(((result * (train > 0) - train) ** 2).sum() / (train > 0).sum())\n",
    "                #print(\"Train score:\", str(iteration) + \" | \" + str(rmse))\n",
    "                \n",
    "#        return MIN_LOSS, MIN_ITER, self.latent_features, self.alpha, self.lambda_reg, self.neg_sampling, self.conf_w\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_split(martix_train, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID = {\n",
    "    'latent_features': [5, 10, 15],\n",
    "    'alpha': [10, 25, 40, 100, 200, 1000],\n",
    "    'lambda_reg': [5, 10, 15, 20, 50],\n",
    "    'conf_w': [1, 5, 10, 20, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344765f2c6b3453fbe77d91fdcbc4c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=450.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = ParameterGrid(GRID)\n",
    "best_score = 999999\n",
    "\n",
    "def grid_search(dict_):\n",
    "    return IALS(**dict_).fit(X_train, X_test)\n",
    "\n",
    "GS = Parallel(n_jobs=-1)(delayed(grid_search)(dict_) for dict_ in tqdm.tqdm(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8695166666651777, 6, 10, 25, 5, 0.85, 1),\n",
       " (0.8706953771223594, 8, 10, 10, 5, 0.85, 20),\n",
       " (0.8708991969948306, 16, 15, 25, 5, 0.85, 1),\n",
       " (0.8712175719863978, 8, 5, 10, 5, 0.85, 20),\n",
       " (0.8712504037270057, 7, 10, 10, 5, 0.85, 10),\n",
       " (0.8716418715089047, 10, 5, 10, 5, 0.85, 50),\n",
       " (0.8716988531174237, 5, 5, 25, 5, 0.85, 1),\n",
       " (0.8721054678992153, 8, 5, 40, 5, 0.85, 1),\n",
       " (0.8724489406357814, 13, 15, 10, 5, 0.85, 10),\n",
       " (0.8730113091855535, 7, 5, 10, 5, 0.85, 10),\n",
       " (0.8732856292401278, 18, 15, 10, 5, 0.85, 20),\n",
       " (0.8738634358006234, 10, 10, 10, 5, 0.85, 50),\n",
       " (0.8744412628713872, 9, 10, 40, 5, 0.85, 1),\n",
       " (0.8751510233697914, 15, 5, 25, 5, 0.85, 5),\n",
       " (0.8759978203050359, 7, 10, 10, 5, 0.85, 5),\n",
       " (0.8763067254854525, 7, 15, 10, 5, 0.85, 5),\n",
       " (0.8777708254734176, 7, 5, 10, 5, 0.85, 5),\n",
       " (0.8783185335303358, 29, 15, 10, 5, 0.85, 50),\n",
       " (0.8787555177458003, 29, 15, 40, 5, 0.85, 1),\n",
       " (0.8807564999242398, 21, 5, 25, 5, 0.85, 10)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(GS, key=lambda x: x[0])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models2 = [\n",
    "        (0.8695166666651777, 6, 10, 25, 5, 0.85, 1),\n",
    "        (0.8706953771223594, 8, 10, 10, 5, 0.85, 20),\n",
    "        (0.8708991969948306, 16, 15, 25, 5, 0.85, 1),\n",
    "        (0.8712175719863978, 8, 5, 10, 5, 0.85, 20),\n",
    "        (0.8712504037270057, 7, 10, 10, 5, 0.85, 10),\n",
    "        (0.8716418715089047, 10, 5, 10, 5, 0.85, 50),\n",
    "        (0.8716988531174237, 5, 5, 25, 5, 0.85, 1),\n",
    "        (0.8721054678992153, 8, 5, 40, 5, 0.85, 1),\n",
    "        (0.8724489406357814, 13, 15, 10, 5, 0.85, 10)]\n",
    "\n",
    "res2 = np.zeros_like(martix_train)\n",
    "\n",
    "for m in models2:\n",
    "    res2 += IALS(m[1] + 5, latent_features=m[2], alpha=m[3], lambda_reg=m[4], neg_sampling=m[5], conf_w=m[6]).fit(martix_train)\n",
    "res2 = res2 / len(models2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IALS:\n",
    "    \n",
    "    def __init__(self, iterations=30, latent_features=5, alpha=25, lambda_reg=10, neg_sampling=0.85, conf_w=10):\n",
    "        self.iterations = iterations\n",
    "        self.latent_features = latent_features\n",
    "        self.alpha = alpha\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.neg_sampling = neg_sampling\n",
    "        self.conf_w = conf_w\n",
    "        np.random.seed(1337)\n",
    "        \n",
    "    def fit(self, train, test=None):\n",
    "        user_size, item_size = train.shape\n",
    "        matrix_full = np.zeros_like(train)\n",
    "        mean_score = train[(train > 0)].mean()\n",
    "        for u in range(user_size):\n",
    "            for i in range(item_size):\n",
    "                if train[u][i]:\n",
    "                    matrix_full[u][i] = train[u][i]\n",
    "                else:\n",
    "                    matrix_full[u][i] = res2[u][i]\n",
    "                    \n",
    "        C = np.ones(train.shape) + self.alpha * np.log(np.ones(train.shape) + train * self.conf_w)\n",
    "        C_I = C - 1\n",
    "        lambda_I = self.lambda_reg * sparse.eye(self.latent_features + 1)\n",
    " \n",
    "        # user u x f\n",
    "        X = np.hstack([np.ones((user_size, 1)), np.random.normal(size=(user_size, self.latent_features))])\n",
    "        # item i x f\n",
    "        Y = np.hstack([np.ones((item_size, 1)), np.random.normal(size=(item_size, self.latent_features))])\n",
    "        # biased als\n",
    "        X_bias = np.array([0] * user_size)\n",
    "        Y_bias = np.array([0] * item_size)\n",
    "        \n",
    "        n_user = (train > 0).sum(1)\n",
    "        n_item = (train > 0).sum(0)\n",
    "        \n",
    "        MIN_LOSS = 9999999\n",
    "        MIN_ITER = 9999\n",
    "        for iteration in range(self.iterations):            \n",
    "            # User step\n",
    "            yTy = np.dot(Y.T, Y)\n",
    "            Cu = C * (matrix_full - Y_bias)\n",
    "            for u in range(user_size):\n",
    "                # X = ((Y.T*Y + Y.T*(C - I) * Y) + lambda*I)^-1 * (Y.T * Cu)\n",
    "                inv = np.linalg.inv(yTy + np.dot(Y.T * C_I[u], Y) + lambda_I * n_user[u])\n",
    "                X[u] = np.dot(np.dot(inv, Y.T), Cu[u].reshape(-1, 1)).ravel()\n",
    "            X_bias = X[:, 0].copy().reshape(-1, 1)\n",
    "            X[:, 0] = 1\n",
    "                \n",
    "            # Item step\n",
    "            xTx = np.dot(X.T, X)\n",
    "            Ci = C * (matrix_full - X_bias)\n",
    "            for i in range(item_size):\n",
    "                # Y = ((X.T*X + X.T*(C - I) * X) + lambda*I)^-1 * (X.T * Ci)\n",
    "                inv = np.linalg.inv(xTx + np.dot(X.T * C_I[:, i], X) + lambda_I * n_item[i])\n",
    "                Y[i] = np.dot(np.dot(inv, X.T), Ci[:, i].reshape(-1, 1)).ravel()\n",
    "            Y_bias = Y[:, 0].copy().ravel()\n",
    "            Y[:, 0] = 1\n",
    "            \n",
    "            result = np.dot(X[:, 1:], Y[:, 1:].T) + X_bias + Y_bias\n",
    "            result[result > 5] = 5\n",
    "            result[result < 1] = 1\n",
    "            \n",
    "            if test is not None:\n",
    "                rmse = np.sqrt(((result * (test > 0) - test) ** 2).sum() / (test > 0).sum())\n",
    "                rmset = np.sqrt(((result * (train > 0) - train) ** 2).sum() / (train > 0).sum())\n",
    "                if rmse < MIN_LOSS:\n",
    "                    MIN_LOSS = rmse\n",
    "                    MIN_ITER = iteration\n",
    "                    #print(\"CUR MIN:\", rmse, iteration, self.latent_features, self.alpha, self.lambda_reg, self.neg_sampling, self.conf_w)\n",
    "                #print(\"Test score:\", str(iteration) + \" | \" + str(rmse) + \" | \" + str(rmset))\n",
    "            else:\n",
    "                rmse = np.sqrt(((result * (train > 0) - train) ** 2).sum() / (train > 0).sum())\n",
    "                #print(\"Train score:\", str(iteration) + \" | \" + str(rmse))\n",
    "                \n",
    "#        return MIN_LOSS, MIN_ITER, self.latent_features, self.alpha, self.lambda_reg, self.neg_sampling, self.conf_w\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID = {\n",
    "    'latent_features': [5, 7, 10],\n",
    "    'alpha': [10, 25, 40, 100],\n",
    "    'lambda_reg': [5, 10, 15, 20, 50],\n",
    "    'conf_w': [1, 5, 10, 20, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcbaadabd2c427ba07b430c3bb94727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = ParameterGrid(GRID)\n",
    "best_score = 999999\n",
    "\n",
    "def grid_search(dict_):\n",
    "    return IALS(**dict_).fit(X_train, X_test)\n",
    "\n",
    "GS = Parallel(n_jobs=-1)(delayed(grid_search)(dict_) for dict_ in tqdm.tqdm(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.863992257220593, 7, 10, 25, 5, 0.85, 1),\n",
       " (0.8650793700851649, 9, 10, 10, 5, 0.85, 20),\n",
       " (0.8652946978087482, 29, 7, 10, 5, 0.85, 20),\n",
       " (0.8656731237902267, 16, 10, 10, 5, 0.85, 10),\n",
       " (0.8656839408271412, 29, 7, 25, 5, 0.85, 1),\n",
       " (0.8664717652537909, 29, 7, 10, 5, 0.85, 50),\n",
       " (0.8667253079476568, 9, 7, 10, 5, 0.85, 10),\n",
       " (0.8671572005137305, 29, 7, 40, 5, 0.85, 1),\n",
       " (0.8676416327991164, 8, 5, 10, 5, 0.85, 20),\n",
       " (0.8678441217620121, 5, 5, 25, 5, 0.85, 1),\n",
       " (0.8681383368549278, 10, 5, 10, 5, 0.85, 50),\n",
       " (0.8683852042823921, 8, 5, 40, 5, 0.85, 1),\n",
       " (0.8683884848023613, 10, 10, 10, 5, 0.85, 50),\n",
       " (0.8687648471973352, 9, 10, 40, 5, 0.85, 1),\n",
       " (0.8693763033094114, 7, 5, 10, 5, 0.85, 10),\n",
       " (0.8708568618900308, 13, 10, 10, 5, 0.85, 5),\n",
       " (0.8716835085320583, 15, 5, 25, 5, 0.85, 5),\n",
       " (0.8720158658786376, 8, 7, 10, 5, 0.85, 5),\n",
       " (0.8723087823646155, 29, 7, 25, 5, 0.85, 5),\n",
       " (0.8740352848385096, 7, 5, 10, 5, 0.85, 5)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(GS, key=lambda x: x[0])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "models3 = [(0.863992257220593, 7, 10, 25, 5, 0.85, 1),\n",
    " (0.8650793700851649, 9, 10, 10, 5, 0.85, 20),\n",
    " (0.8652946978087482, 29, 7, 10, 5, 0.85, 20),\n",
    " (0.8656731237902267, 16, 10, 10, 5, 0.85, 10),\n",
    " (0.8656839408271412, 29, 7, 25, 5, 0.85, 1)]\n",
    "\n",
    "res3 = np.zeros_like(martix_train)\n",
    "\n",
    "for m in models3:\n",
    "    res3 += IALS(m[1] + 5, latent_features=m[2], alpha=m[3], lambda_reg=m[4], neg_sampling=m[5], conf_w=m[6]).fit(martix_train)\n",
    "res3 = res3 / len(models3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IALS:\n",
    "    \n",
    "    def __init__(self, iterations=30, latent_features=5, alpha=25, lambda_reg=10, neg_sampling=0.85, conf_w=10):\n",
    "        self.iterations = iterations\n",
    "        self.latent_features = latent_features\n",
    "        self.alpha = alpha\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.neg_sampling = neg_sampling\n",
    "        self.conf_w = conf_w\n",
    "        np.random.seed(1337)\n",
    "        \n",
    "    def fit(self, train, test=None):\n",
    "        user_size, item_size = train.shape\n",
    "        matrix_full = np.zeros_like(train)\n",
    "        mean_score = train[(train > 0)].mean()\n",
    "        for u in range(user_size):\n",
    "            for i in range(item_size):\n",
    "                if train[u][i]:\n",
    "                    matrix_full[u][i] = train[u][i]\n",
    "                else:\n",
    "                    matrix_full[u][i] = res3[u][i]\n",
    "                    \n",
    "        C = np.ones(train.shape) + self.alpha * np.log(np.ones(train.shape) + train * self.conf_w)\n",
    "        C_I = C - 1\n",
    "        lambda_I = self.lambda_reg * sparse.eye(self.latent_features + 1)\n",
    " \n",
    "        # user u x f\n",
    "        X = np.hstack([np.ones((user_size, 1)), np.random.normal(size=(user_size, self.latent_features))])\n",
    "        # item i x f\n",
    "        Y = np.hstack([np.ones((item_size, 1)), np.random.normal(size=(item_size, self.latent_features))])\n",
    "        # biased als\n",
    "        X_bias = np.array([0] * user_size)\n",
    "        Y_bias = np.array([0] * item_size)\n",
    "        \n",
    "        n_user = (train > 0).sum(1)\n",
    "        n_item = (train > 0).sum(0)\n",
    "        \n",
    "        MIN_LOSS = 9999999\n",
    "        MIN_ITER = 9999\n",
    "        for iteration in range(self.iterations):            \n",
    "            # User step\n",
    "            yTy = np.dot(Y.T, Y)\n",
    "            Cu = C * (matrix_full - Y_bias)\n",
    "            for u in range(user_size):\n",
    "                # X = ((Y.T*Y + Y.T*(C - I) * Y) + lambda*I)^-1 * (Y.T * Cu)\n",
    "                inv = np.linalg.inv(yTy + np.dot(Y.T * C_I[u], Y) + lambda_I * n_user[u])\n",
    "                X[u] = np.dot(np.dot(inv, Y.T), Cu[u].reshape(-1, 1)).ravel()\n",
    "            X_bias = X[:, 0].copy().reshape(-1, 1)\n",
    "            X[:, 0] = 1\n",
    "                \n",
    "            # Item step\n",
    "            xTx = np.dot(X.T, X)\n",
    "            Ci = C * (matrix_full - X_bias)\n",
    "            for i in range(item_size):\n",
    "                # Y = ((X.T*X + X.T*(C - I) * X) + lambda*I)^-1 * (X.T * Ci)\n",
    "                inv = np.linalg.inv(xTx + np.dot(X.T * C_I[:, i], X) + lambda_I * n_item[i])\n",
    "                Y[i] = np.dot(np.dot(inv, X.T), Ci[:, i].reshape(-1, 1)).ravel()\n",
    "            Y_bias = Y[:, 0].copy().ravel()\n",
    "            Y[:, 0] = 1\n",
    "            \n",
    "            result = np.dot(X[:, 1:], Y[:, 1:].T) + X_bias + Y_bias\n",
    "            result[result > 5] = 5\n",
    "            result[result < 1] = 1\n",
    "            \n",
    "            if test is not None:\n",
    "                rmse = np.sqrt(((result * (test > 0) - test) ** 2).sum() / (test > 0).sum())\n",
    "                rmset = np.sqrt(((result * (train > 0) - train) ** 2).sum() / (train > 0).sum())\n",
    "                if rmse < MIN_LOSS:\n",
    "                    MIN_LOSS = rmse\n",
    "                    MIN_ITER = iteration\n",
    "                    #print(\"CUR MIN:\", rmse, iteration, self.latent_features, self.alpha, self.lambda_reg, self.neg_sampling, self.conf_w)\n",
    "                #print(\"Test score:\", str(iteration) + \" | \" + str(rmse) + \" | \" + str(rmset))\n",
    "            else:\n",
    "                rmse = np.sqrt(((result * (train > 0) - train) ** 2).sum() / (train > 0).sum())\n",
    "                #print(\"Train score:\", str(iteration) + \" | \" + str(rmse))\n",
    "                \n",
    "#        return MIN_LOSS, MIN_ITER, self.latent_features, self.alpha, self.lambda_reg, self.neg_sampling, self.conf_w\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c940509fb34f40beaa729f6cc1814556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = ParameterGrid(GRID)\n",
    "best_score = 999999\n",
    "\n",
    "def grid_search(dict_):\n",
    "    return IALS(**dict_).fit(X_train, X_test)\n",
    "\n",
    "GS = Parallel(n_jobs=-1)(delayed(grid_search)(dict_) for dict_ in tqdm.tqdm(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8590039812704885, 21, 10, 25, 5, 0.85, 1),\n",
       " (0.8602428603305463, 29, 10, 10, 5, 0.85, 20),\n",
       " (0.8610594900181323, 21, 10, 10, 5, 0.85, 10),\n",
       " (0.8617264440522253, 11, 7, 10, 5, 0.85, 20),\n",
       " (0.8619964624280274, 8, 7, 25, 5, 0.85, 1),\n",
       " (0.862630239303434, 29, 7, 10, 5, 0.85, 50),\n",
       " (0.8630380802883397, 29, 7, 40, 5, 0.85, 1),\n",
       " (0.8632158965195386, 9, 7, 10, 5, 0.85, 10),\n",
       " (0.8635185414064538, 27, 10, 10, 5, 0.85, 50),\n",
       " (0.8635434876215294, 29, 10, 40, 5, 0.85, 1),\n",
       " (0.8663287241736828, 5, 5, 25, 5, 0.85, 1),\n",
       " (0.866476531144437, 8, 5, 10, 5, 0.85, 20),\n",
       " (0.866905435785169, 8, 5, 40, 5, 0.85, 1),\n",
       " (0.8669341950873642, 14, 10, 10, 5, 0.85, 5),\n",
       " (0.8670307396590826, 10, 5, 10, 5, 0.85, 50),\n",
       " (0.8682358431524588, 7, 5, 10, 5, 0.85, 10),\n",
       " (0.8684422086675153, 29, 7, 25, 5, 0.85, 5),\n",
       " (0.8687711618818741, 8, 7, 10, 5, 0.85, 5),\n",
       " (0.8705952635733107, 14, 5, 25, 5, 0.85, 5),\n",
       " (0.8729954751782127, 7, 5, 10, 5, 0.85, 5)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(GS, key=lambda x: x[0])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "models4 = [(0.8590039812704885, 21, 10, 25, 5, 0.85, 1),\n",
    " (0.8602428603305463, 29, 10, 10, 5, 0.85, 20),\n",
    " (0.8610594900181323, 21, 10, 10, 5, 0.85, 10),\n",
    " (0.8617264440522253, 11, 7, 10, 5, 0.85, 20),\n",
    " (0.8619964624280274, 8, 7, 25, 5, 0.85, 1)]\n",
    "\n",
    "res4 = np.zeros_like(martix_train)\n",
    "\n",
    "for m in models4:\n",
    "    res4 += IALS(m[1] + 5, latent_features=m[2], alpha=m[3], lambda_reg=m[4], neg_sampling=m[5], conf_w=m[6]).fit(martix_train)\n",
    "res4 = res4 / len(models4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IALS:\n",
    "    \n",
    "    def __init__(self, iterations=30, latent_features=5, alpha=25, lambda_reg=10, neg_sampling=0.85, conf_w=10):\n",
    "        self.iterations = iterations\n",
    "        self.latent_features = latent_features\n",
    "        self.alpha = alpha\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.neg_sampling = neg_sampling\n",
    "        self.conf_w = conf_w\n",
    "        np.random.seed(1337)\n",
    "        \n",
    "    def fit(self, train, test=None):\n",
    "        user_size, item_size = train.shape\n",
    "        matrix_full = np.zeros_like(train)\n",
    "        mean_score = train[(train > 0)].mean()\n",
    "        for u in range(user_size):\n",
    "            for i in range(item_size):\n",
    "                if train[u][i]:\n",
    "                    matrix_full[u][i] = train[u][i]\n",
    "                else:\n",
    "                    matrix_full[u][i] = res4[u][i]\n",
    "                    \n",
    "        C = np.ones(train.shape) + self.alpha * np.log(np.ones(train.shape) + train * self.conf_w)\n",
    "        C_I = C - 1\n",
    "        lambda_I = self.lambda_reg * sparse.eye(self.latent_features + 1)\n",
    " \n",
    "        # user u x f\n",
    "        X = np.hstack([np.ones((user_size, 1)), np.random.normal(size=(user_size, self.latent_features))])\n",
    "        # item i x f\n",
    "        Y = np.hstack([np.ones((item_size, 1)), np.random.normal(size=(item_size, self.latent_features))])\n",
    "        # biased als\n",
    "        X_bias = np.array([0] * user_size)\n",
    "        Y_bias = np.array([0] * item_size)\n",
    "        \n",
    "        n_user = (train > 0).sum(1)\n",
    "        n_item = (train > 0).sum(0)\n",
    "        \n",
    "        MIN_LOSS = 9999999\n",
    "        MIN_ITER = 9999\n",
    "        for iteration in range(self.iterations):            \n",
    "            # User step\n",
    "            yTy = np.dot(Y.T, Y)\n",
    "            Cu = C * (matrix_full - Y_bias)\n",
    "            for u in range(user_size):\n",
    "                # X = ((Y.T*Y + Y.T*(C - I) * Y) + lambda*I)^-1 * (Y.T * Cu)\n",
    "                inv = np.linalg.inv(yTy + np.dot(Y.T * C_I[u], Y) + lambda_I * n_user[u])\n",
    "                X[u] = np.dot(np.dot(inv, Y.T), Cu[u].reshape(-1, 1)).ravel()\n",
    "            X_bias = X[:, 0].copy().reshape(-1, 1)\n",
    "            X[:, 0] = 1\n",
    "                \n",
    "            # Item step\n",
    "            xTx = np.dot(X.T, X)\n",
    "            Ci = C * (matrix_full - X_bias)\n",
    "            for i in range(item_size):\n",
    "                # Y = ((X.T*X + X.T*(C - I) * X) + lambda*I)^-1 * (X.T * Ci)\n",
    "                inv = np.linalg.inv(xTx + np.dot(X.T * C_I[:, i], X) + lambda_I * n_item[i])\n",
    "                Y[i] = np.dot(np.dot(inv, X.T), Ci[:, i].reshape(-1, 1)).ravel()\n",
    "            Y_bias = Y[:, 0].copy().ravel()\n",
    "            Y[:, 0] = 1\n",
    "            \n",
    "            result = np.dot(X[:, 1:], Y[:, 1:].T) + X_bias + Y_bias\n",
    "            result[result > 5] = 5\n",
    "            result[result < 1] = 1\n",
    "            \n",
    "            if test is not None:\n",
    "                rmse = np.sqrt(((result * (test > 0) - test) ** 2).sum() / (test > 0).sum())\n",
    "                rmset = np.sqrt(((result * (train > 0) - train) ** 2).sum() / (train > 0).sum())\n",
    "                if rmse < MIN_LOSS:\n",
    "                    MIN_LOSS = rmse\n",
    "                    MIN_ITER = iteration\n",
    "                    #print(\"CUR MIN:\", rmse, iteration, self.latent_features, self.alpha, self.lambda_reg, self.neg_sampling, self.conf_w)\n",
    "                #print(\"Test score:\", str(iteration) + \" | \" + str(rmse) + \" | \" + str(rmset))\n",
    "            else:\n",
    "                rmse = np.sqrt(((result * (train > 0) - train) ** 2).sum() / (train > 0).sum())\n",
    "                #print(\"Train score:\", str(iteration) + \" | \" + str(rmse))\n",
    "                \n",
    "#        return MIN_LOSS, MIN_ITER, self.latent_features, self.alpha, self.lambda_reg, self.neg_sampling, self.conf_w\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6250aded93410da294c8092da1a912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = ParameterGrid(GRID)\n",
    "best_score = 999999\n",
    "\n",
    "def grid_search(dict_):\n",
    "    return IALS(**dict_).fit(X_train, X_test)\n",
    "\n",
    "GS = Parallel(n_jobs=-1)(delayed(grid_search)(dict_) for dict_ in tqdm.tqdm(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8567797690357618, 24, 10, 25, 5, 0.85, 1),\n",
       " (0.8580482210831184, 18, 10, 10, 5, 0.85, 20),\n",
       " (0.8592542326509288, 29, 10, 10, 5, 0.85, 10),\n",
       " (0.8595163283424511, 10, 7, 10, 5, 0.85, 20),\n",
       " (0.8602064592213389, 8, 7, 25, 5, 0.85, 1),\n",
       " (0.8603136032224314, 29, 10, 40, 5, 0.85, 1),\n",
       " (0.8605204157779973, 29, 10, 10, 5, 0.85, 50),\n",
       " (0.8608077734072278, 18, 7, 10, 5, 0.85, 50),\n",
       " (0.8610604244554132, 29, 7, 40, 5, 0.85, 1),\n",
       " (0.8613843223210341, 9, 7, 10, 5, 0.85, 10),\n",
       " (0.8654291675826731, 20, 10, 10, 5, 0.85, 5),\n",
       " (0.8656378977244835, 5, 5, 25, 5, 0.85, 1),\n",
       " (0.8658982410690396, 8, 5, 10, 5, 0.85, 20),\n",
       " (0.8660947310218461, 29, 7, 25, 5, 0.85, 5),\n",
       " (0.8662835832704237, 8, 5, 40, 5, 0.85, 1),\n",
       " (0.8665038052266019, 11, 5, 10, 5, 0.85, 50),\n",
       " (0.867206310540381, 8, 7, 10, 5, 0.85, 5),\n",
       " (0.8676293747653046, 7, 5, 10, 5, 0.85, 10),\n",
       " (0.870116421243002, 15, 5, 25, 5, 0.85, 5),\n",
       " (0.871451777046329, 29, 10, 25, 5, 0.85, 5)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(GS, key=lambda x: x[0])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "models5 = [(0.8567797690357618, 24, 10, 25, 5, 0.85, 1),\n",
    "         (0.8595163283424511, 10, 7, 10, 5, 0.85, 20),\n",
    "         (0.8602064592213389, 8, 7, 25, 5, 0.85, 1)]\n",
    "\n",
    "res5 = np.zeros_like(martix_train)\n",
    "\n",
    "for m in models5:\n",
    "    res5 += IALS(m[1] + 5, latent_features=m[2], alpha=m[3], lambda_reg=m[4], neg_sampling=m[5], conf_w=m[6]).fit(martix_train)\n",
    "res5 = res5 / len(models5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = []\n",
    "for i, idx in enumerate(test.values):\n",
    "    y_test_pred.append(res5[idx[0]-1][idx[1]-1])\n",
    "pred = pd.DataFrame({'Id': range(1, len(y_test_pred)+1), 'Score': y_test_pred})\n",
    "pred.to_csv('submission.txt', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
